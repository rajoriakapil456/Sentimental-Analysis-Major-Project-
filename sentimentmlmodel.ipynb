{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentimentmlmodel.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1qLoS8g3vgPPdHrGktmdqMhDbTlbheVC0","authorship_tag":"ABX9TyOybUD4rhVPGk/VWrSWDwZy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYiNSbbSjfjA","executionInfo":{"status":"ok","timestamp":1655105685962,"user_tz":-330,"elapsed":501,"user":{"displayName":"kapil rajoria","userId":"07863991955522170728"}},"outputId":"b16b3167-c8af-4664-dc5c-dd81e184ac10"},"source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","import numpy as np\n","import pandas as pd\n","dataset=pd.read_csv('/content/drive/My Drive/a1_RestaurantReviews_HistoricDump.tsv',delimiter='\\t',quoting=3)\n","#dataset.shape\n","#dataset.head()\n","#data cleaning--->\n","import re\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","ps=PorterStemmer()\n","all_stopwords=stopwords.words('english')\n","all_stopwords.remove('not')\n","#list to store cleaned data\n","corpus=[]\n","for i in range(0,900):\n","  review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n","  review = review.lower()\n","  review = review.split()\n","  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n","  review = ' '.join(review)\n","  corpus.append(review)\n","#data transformation--->\n","from sklearn.feature_extraction.text import CountVectorizer\n","#to make bag of words containing 1420 word tokens \n","#1420 only to reduce sparsity\n","#1420 by hit and trial\n","cv=CountVectorizer(max_features=1420)\n","#X=bag of words representation of our reviews\n","X=cv.fit_transform(corpus).toarray()\n","#Y=historical labels\n","Y=dataset.iloc[:,-1].values\n","#now saving this bow dictionary, to later use in prediction\n","import pickle\n","bow_path='./drive/MyDrive/c1_BoW_Sentiment_Model.pkl'\n","pickle.dump(cv,open(bow_path,'wb'))\n","pickle_file = open(\"./drive/MyDrive/c1_BoW_Sentiment_Model.pkl\", \"rb\")\n","#dividing dataset into training and testing\n","#0.20 means 20 percent testing\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 0)\n","#model fitting(Naive Byes)\n","from sklearn.naive_bayes import GaussianNB\n","classifier = GaussianNB()\n","classifier.fit(X_train, y_train)\n","#exporting NB classifier to later use in prediction\n","import joblib\n","joblib.dump(classifier, './drive/MyDrive/c2_Classifier_Sentiment_Model') \n","#testing our model performance\n","y_pred = classifier.predict(X_test)\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)\n","print(cm)\n","accuracy_score(y_test, y_pred)\n","#0.72777 means accuracy is 72%"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[[67 11]\n"," [38 64]]\n"]},{"output_type":"execute_result","data":{"text/plain":["0.7277777777777777"]},"metadata":{},"execution_count":6}]}]}